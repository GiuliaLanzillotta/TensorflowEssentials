{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed computation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYahlcMNNIPfb5esn6H1xW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaLanzillotta/TensorflowEssentials/blob/master/Distributed_computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxJc2x7KxSp",
        "colab_type": "text"
      },
      "source": [
        "# Distributing Tensorflow computation\n",
        "\n",
        "> [Tensorflow] gives you full control over how to split (or replicate) your computation graph across devices and servers, and it lets you parallelize and synchronize operations in flexible ways so you can choose between all sorts of parallelization approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjjzpinbLMFk",
        "colab_type": "text"
      },
      "source": [
        "## Parallelizing simple graphs across several GPUs on a single machine.\n",
        "\n",
        "In order to run TensorFlow on multiple GPU cards, you first need to make sure your GPU cards have NVidia Compute Capability.\n",
        "You must then **download and install the appropriate version of the CUDA and cuDNN libraries**, and set a few environment variables so TensorFlow knows where to find CUDA and cuDNN. \n",
        "\n",
        "> #### What is CUDA?  \n",
        "Short for \"Compute Unified Device Architecture\", it's both a parallel computing platform and a library created  by Nvidia allowing developers to use CUDA-enabled GPUs for general purpose processing. The CUDA platform is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels. \n",
        "\n",
        "> #### What about CuDNN?\n",
        "Short for CUDA Deep Neural Network library, a GPU-accelerated library of primitives for DNNs created by Nvidia. It provides optimized implementations of common DNN computations such as activation layers, normalization, forward and backward convolutions, and pooling.\n",
        "\n",
        "Let's look at what the Google server we're running on has to offer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX6FDvyvIGLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "739c9989-7403-48f0-a580-dd7274087d22"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 23 13:30:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE9lQAjJK5pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "158948d1-1e32-4b06-ac22-1aca45e156f8"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPJ4yfkPxaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b7b75a81-5958-4e22-f45f-de1cbe9bd12f"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.list_devices()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 11864881681466060498),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1397507663453625933),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 7947584449248635740),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11330115994, 10096098157676641914)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCSlwI1bSZWH",
        "colab_type": "text"
      },
      "source": [
        "    Side note: \n",
        "    to test the following code snippets \n",
        "    I am going to use a python script \n",
        "    that builds and trains a DNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglatpauQEHF",
        "colab_type": "text"
      },
      "source": [
        "### Managing GPU RAM \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSp-q9hsQMXr",
        "colab_type": "text"
      },
      "source": [
        "To avoid that each Tensorflow process occupies the whole GPU RAM we can force each process to run on a single GPU card.<br>\n",
        "We can obtain it by setting the ```CUDA_VISIBLE_DEVICES``` environment variable as follows:\n",
        "\n",
        "```CUDA_VISIBLE_DEVICES=0,1 python3 program_1.py```\n",
        "\n",
        "```CUDA_VISIBLE_DEVICES=3,2 python3 program_2.py```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vode_MORP3H",
        "colab_type": "text"
      },
      "source": [
        "Another option is to tell TensorFlow to grab only a fraction of the memory. \n",
        "The following code does the job:\n",
        "\n",
        "```\n",
        "    # At the beginning of the script:\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 0.5 \n",
        "    # And when you create a session:\n",
        "    session = tf.Session(config=config)\n",
        "  ```\n",
        "I added the above code in the ```dnn.py``` script and in the following cell I am running it twice (I know it doesn't really make sense, but it serves the point).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxuBboIGSFJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be4acbab-07d7-43a2-dd4c-2aaa3a7add00"
      },
      "source": [
        "!python3 dnn.py & python3 dnn.py  & nvidia-smi"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 23 13:57:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    58W / 149W |     69MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "WARNING:tensorflow:From dnn.py:22: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:22: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:51: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:51: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:93: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:93: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:100: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:100: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:117: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:118: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:117: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:118: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:129: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From dnn.py:129: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From dnn.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-23 13:57:20.589172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-23 13:57:20.589671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15cad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.589863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-23 13:57:20.594050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-23 13:57:20.599698: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-23 13:57:20.600135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23f0d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.600305: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-23 13:57:20.603542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-23 13:57:20.670663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.672050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15caf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.672087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-23 13:57:20.672459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.673219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-23 13:57:20.673684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.676667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:20.679730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-23 13:57:20.680384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-23 13:57:20.683925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-23 13:57:20.685195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-23 13:57:20.690967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-23 13:57:20.691168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.692455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.693649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-23 13:57:20.693891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.693996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.695983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23f0f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.696024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-23 13:57:20.696282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.697084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-23 13:57:20.697398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.698343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-23 13:57:20.698596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-23 13:57:20.698808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-23 13:57:20.699327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.699546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:20.700765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.701125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-23 13:57:20.701577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-23 13:57:20.702212: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-23 13:57:20.702482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5720 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2020-04-23 13:57:20.703416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-23 13:57:20.704450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-23 13:57:20.708771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-23 13:57:20.708963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.709952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.710788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-23 13:57:20.710894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.712691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-23 13:57:20.712732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-23 13:57:20.712755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-23 13:57:20.712981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.714735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.715865: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-23 13:57:20.715920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5720 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From dnn.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2020-04-23 13:57:21.531883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:21.540723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "0 Train accuracy: 0.66 Test accuracy: 0.7465\n",
            "0 Train accuracy: 0.9 Test accuracy: 0.7593\n",
            "1 Train accuracy: 0.86 Test accuracy: 0.8348\n",
            "1 Train accuracy: 0.74 Test accuracy: 0.8427\n",
            "2 Train accuracy: 0.88 Test accuracy: 0.8644\n",
            "2 Train accuracy: 0.82 Test accuracy: 0.8683\n",
            "3 Train accuracy: 0.76 Test accuracy: 0.8806\n",
            "3 Train accuracy: 0.86 Test accuracy: 0.8823\n",
            "4 Train accuracy: 0.88 Test accuracy: 0.8904\n",
            "4 Train accuracy: 0.86 Test accuracy: 0.8928\n",
            "5 Train accuracy: 0.92 Test accuracy: 0.8969\n",
            "5 Train accuracy: 0.94 Test accuracy: 0.8988\n",
            "6 Train accuracy: 0.9 Test accuracy: 0.9018\n",
            "6 Train accuracy: 0.88 Test accuracy: 0.9033\n",
            "7 Train accuracy: 0.9 Test accuracy: 0.9068\n",
            "7 Train accuracy: 0.88 Test accuracy: 0.907\n",
            "8 Train accuracy: 0.92 Test accuracy: 0.9108\n",
            "8 Train accuracy: 0.92 Test accuracy: 0.9104\n",
            "9 Train accuracy: 0.96 Test accuracy: 0.9142\n",
            "9 Train accuracy: 0.9 Test accuracy: 0.9125\n",
            "10 Train accuracy: 0.9 Test accuracy: 0.9176\n",
            "10 Train accuracy: 0.92 Test accuracy: 0.914\n",
            "11 Train accuracy: 0.9 Test accuracy: 0.9189\n",
            "11 Train accuracy: 0.9 Test accuracy: 0.9167\n",
            "12 Train accuracy: 0.94 Test accuracy: 0.9213\n",
            "12 Train accuracy: 0.92 Test accuracy: 0.9178\n",
            "13 Train accuracy: 0.92 Test accuracy: 0.9232\n",
            "13 Train accuracy: 0.92 Test accuracy: 0.9194\n",
            "14 Train accuracy: 0.9 Test accuracy: 0.9246\n",
            "14 Train accuracy: 0.96 Test accuracy: 0.9208\n",
            "15 Train accuracy: 0.92 Test accuracy: 0.9264\n",
            "15 Train accuracy: 0.92 Test accuracy: 0.9228\n",
            "16 Train accuracy: 0.96 Test accuracy: 0.9279\n",
            "16 Train accuracy: 0.92 Test accuracy: 0.9243\n",
            "17 Train accuracy: 0.94 Test accuracy: 0.9291\n",
            "17 Train accuracy: 0.86 Test accuracy: 0.9251\n",
            "18 Train accuracy: 0.98 Test accuracy: 0.9305\n",
            "18 Train accuracy: 0.94 Test accuracy: 0.9266\n",
            "19 Train accuracy: 0.9 Test accuracy: 0.9314\n",
            "19 Train accuracy: 0.94 Test accuracy: 0.9277\n",
            "20 Train accuracy: 0.92 Test accuracy: 0.9326\n",
            "20 Train accuracy: 0.92 Test accuracy: 0.9286\n",
            "21 Train accuracy: 0.92 Test accuracy: 0.9343\n",
            "21 Train accuracy: 0.96 Test accuracy: 0.9296\n",
            "22 Train accuracy: 0.92 Test accuracy: 0.9355\n",
            "22 Train accuracy: 0.94 Test accuracy: 0.9309\n",
            "23 Train accuracy: 0.94 Test accuracy: 0.9358\n",
            "23 Train accuracy: 0.8 Test accuracy: 0.931\n",
            "24 Train accuracy: 0.96 Test accuracy: 0.9362\n",
            "24 Train accuracy: 1.0 Test accuracy: 0.9313\n",
            "25 Train accuracy: 0.94 Test accuracy: 0.9374\n",
            "25 Train accuracy: 1.0 Test accuracy: 0.934\n",
            "26 Train accuracy: 0.92 Test accuracy: 0.938\n",
            "26 Train accuracy: 0.84 Test accuracy: 0.9334\n",
            "27 Train accuracy: 0.88 Test accuracy: 0.9383\n",
            "27 Train accuracy: 0.96 Test accuracy: 0.9349\n",
            "28 Train accuracy: 0.96 Test accuracy: 0.9395\n",
            "28 Train accuracy: 0.96 Test accuracy: 0.9353\n",
            "29 Train accuracy: 0.9 Test accuracy: 0.939\n",
            "29 Train accuracy: 0.98 Test accuracy: 0.9364\n",
            "30 Train accuracy: 0.94 Test accuracy: 0.9404\n",
            "30 Train accuracy: 0.96 Test accuracy: 0.9369\n",
            "31 Train accuracy: 0.92 Test accuracy: 0.9402\n",
            "31 Train accuracy: 0.98 Test accuracy: 0.9366\n",
            "32 Train accuracy: 0.98 Test accuracy: 0.9417\n",
            "32 Train accuracy: 0.96 Test accuracy: 0.9369\n",
            "33 Train accuracy: 0.96 Test accuracy: 0.9418\n",
            "33 Train accuracy: 0.98 Test accuracy: 0.9379\n",
            "34 Train accuracy: 0.9 Test accuracy: 0.9417\n",
            "34 Train accuracy: 0.88 Test accuracy: 0.9397\n",
            "35 Train accuracy: 0.94 Test accuracy: 0.9425\n",
            "35 Train accuracy: 0.94 Test accuracy: 0.9396\n",
            "36 Train accuracy: 0.96 Test accuracy: 0.9435\n",
            "36 Train accuracy: 0.92 Test accuracy: 0.9402\n",
            "37 Train accuracy: 0.96 Test accuracy: 0.9443\n",
            "37 Train accuracy: 0.96 Test accuracy: 0.9402\n",
            "38 Train accuracy: 0.9 Test accuracy: 0.9447\n",
            "38 Train accuracy: 0.96 Test accuracy: 0.9412\n",
            "39 Train accuracy: 0.96 Test accuracy: 0.9457\n",
            "39 Train accuracy: 0.92 Test accuracy: 0.9423\n",
            "40 Train accuracy: 0.94 Test accuracy: 0.9458\n",
            "40 Train accuracy: 0.88 Test accuracy: 0.9421\n",
            "41 Train accuracy: 0.98 Test accuracy: 0.9448\n",
            "41 Train accuracy: 0.96 Test accuracy: 0.9426\n",
            "42 Train accuracy: 0.98 Test accuracy: 0.9466\n",
            "42 Train accuracy: 0.96 Test accuracy: 0.9422\n",
            "43 Train accuracy: 0.96 Test accuracy: 0.9476\n",
            "43 Train accuracy: 0.88 Test accuracy: 0.9436\n",
            "44 Train accuracy: 0.96 Test accuracy: 0.9473\n",
            "44 Train accuracy: 0.9 Test accuracy: 0.9432\n",
            "45 Train accuracy: 0.94 Test accuracy: 0.9482\n",
            "45 Train accuracy: 1.0 Test accuracy: 0.9446\n",
            "46 Train accuracy: 0.96 Test accuracy: 0.9485\n",
            "46 Train accuracy: 0.94 Test accuracy: 0.9453\n",
            "47 Train accuracy: 0.96 Test accuracy: 0.9499\n",
            "47 Train accuracy: 0.94 Test accuracy: 0.945\n",
            "48 Train accuracy: 0.94 Test accuracy: 0.9493\n",
            "48 Train accuracy: 0.96 Test accuracy: 0.9453\n",
            "49 Train accuracy: 0.96 Test accuracy: 0.9493\n",
            "49 Train accuracy: 0.94 Test accuracy: 0.9457\n",
            "50 Train accuracy: 0.98 Test accuracy: 0.9493\n",
            "50 Train accuracy: 0.98 Test accuracy: 0.9464\n",
            "51 Train accuracy: 0.92 Test accuracy: 0.9513\n",
            "51 Train accuracy: 0.96 Test accuracy: 0.9469\n",
            "52 Train accuracy: 0.98 Test accuracy: 0.9522\n",
            "52 Train accuracy: 1.0 Test accuracy: 0.9473\n",
            "53 Train accuracy: 0.92 Test accuracy: 0.9517\n",
            "53 Train accuracy: 0.98 Test accuracy: 0.9476\n",
            "54 Train accuracy: 0.96 Test accuracy: 0.9522\n",
            "54 Train accuracy: 0.96 Test accuracy: 0.948\n",
            "55 Train accuracy: 0.96 Test accuracy: 0.9524\n",
            "55 Train accuracy: 0.96 Test accuracy: 0.9489\n",
            "56 Train accuracy: 0.96 Test accuracy: 0.9527\n",
            "56 Train accuracy: 0.96 Test accuracy: 0.9486\n",
            "57 Train accuracy: 0.98 Test accuracy: 0.9536\n",
            "57 Train accuracy: 0.98 Test accuracy: 0.9494\n",
            "58 Train accuracy: 0.98 Test accuracy: 0.9543\n",
            "58 Train accuracy: 0.9 Test accuracy: 0.9499\n",
            "59 Train accuracy: 0.98 Test accuracy: 0.9546\n",
            "59 Train accuracy: 0.98 Test accuracy: 0.9504\n",
            "60 Train accuracy: 0.94 Test accuracy: 0.9543\n",
            "60 Train accuracy: 0.98 Test accuracy: 0.9504\n",
            "61 Train accuracy: 0.96 Test accuracy: 0.9549\n",
            "61 Train accuracy: 0.96 Test accuracy: 0.9506\n",
            "62 Train accuracy: 0.98 Test accuracy: 0.9547\n",
            "62 Train accuracy: 0.96 Test accuracy: 0.9518\n",
            "63 Train accuracy: 0.98 Test accuracy: 0.9558\n",
            "63 Train accuracy: 0.98 Test accuracy: 0.9519\n",
            "64 Train accuracy: 0.98 Test accuracy: 0.956\n",
            "64 Train accuracy: 1.0 Test accuracy: 0.9523\n",
            "65 Train accuracy: 0.98 Test accuracy: 0.9557\n",
            "65 Train accuracy: 0.96 Test accuracy: 0.9529\n",
            "66 Train accuracy: 0.92 Test accuracy: 0.9563\n",
            "66 Train accuracy: 1.0 Test accuracy: 0.9523\n",
            "67 Train accuracy: 0.96 Test accuracy: 0.9565\n",
            "67 Train accuracy: 0.96 Test accuracy: 0.9527\n",
            "68 Train accuracy: 0.96 Test accuracy: 0.9565\n",
            "68 Train accuracy: 1.0 Test accuracy: 0.9535\n",
            "69 Train accuracy: 0.94 Test accuracy: 0.957\n",
            "69 Train accuracy: 0.94 Test accuracy: 0.9538\n",
            "70 Train accuracy: 0.94 Test accuracy: 0.9577\n",
            "70 Train accuracy: 0.98 Test accuracy: 0.9549\n",
            "71 Train accuracy: 1.0 Test accuracy: 0.9574\n",
            "71 Train accuracy: 0.94 Test accuracy: 0.9544\n",
            "72 Train accuracy: 0.94 Test accuracy: 0.9576\n",
            "72 Train accuracy: 1.0 Test accuracy: 0.955\n",
            "73 Train accuracy: 0.94 Test accuracy: 0.9573\n",
            "73 Train accuracy: 0.98 Test accuracy: 0.9563\n",
            "74 Train accuracy: 0.86 Test accuracy: 0.9579\n",
            "74 Train accuracy: 0.92 Test accuracy: 0.9557\n",
            "75 Train accuracy: 0.96 Test accuracy: 0.958\n",
            "75 Train accuracy: 0.94 Test accuracy: 0.956\n",
            "76 Train accuracy: 0.98 Test accuracy: 0.958\n",
            "76 Train accuracy: 0.96 Test accuracy: 0.9563\n",
            "77 Train accuracy: 0.96 Test accuracy: 0.9584\n",
            "77 Train accuracy: 0.92 Test accuracy: 0.9565\n",
            "78 Train accuracy: 0.96 Test accuracy: 0.9568\n",
            "78 Train accuracy: 1.0 Test accuracy: 0.9589\n",
            "79 Train accuracy: 0.98 Test accuracy: 0.9574\n",
            "79 Train accuracy: 0.98 Test accuracy: 0.9598\n",
            "80 Train accuracy: 0.94 Test accuracy: 0.9577\n",
            "80 Train accuracy: 0.98 Test accuracy: 0.9591\n",
            "81 Train accuracy: 0.96 Test accuracy: 0.9577\n",
            "81 Train accuracy: 0.94 Test accuracy: 0.9598\n",
            "82 Train accuracy: 0.98 Test accuracy: 0.9578\n",
            "82 Train accuracy: 0.94 Test accuracy: 0.9596\n",
            "83 Train accuracy: 0.96 Test accuracy: 0.9588\n",
            "83 Train accuracy: 0.98 Test accuracy: 0.9598\n",
            "84 Train accuracy: 0.98 Test accuracy: 0.9584\n",
            "84 Train accuracy: 0.96 Test accuracy: 0.96\n",
            "85 Train accuracy: 0.98 Test accuracy: 0.9586\n",
            "85 Train accuracy: 0.96 Test accuracy: 0.96\n",
            "86 Train accuracy: 0.94 Test accuracy: 0.9591\n",
            "86 Train accuracy: 1.0 Test accuracy: 0.9608\n",
            "87 Train accuracy: 1.0 Test accuracy: 0.9604\n",
            "87 Train accuracy: 0.98 Test accuracy: 0.961\n",
            "88 Train accuracy: 1.0 Test accuracy: 0.9597\n",
            "88 Train accuracy: 0.98 Test accuracy: 0.9615\n",
            "89 Train accuracy: 0.98 Test accuracy: 0.9604\n",
            "89 Train accuracy: 0.96 Test accuracy: 0.9618\n",
            "90 Train accuracy: 0.98 Test accuracy: 0.9606\n",
            "90 Train accuracy: 0.96 Test accuracy: 0.9608\n",
            "91 Train accuracy: 0.98 Test accuracy: 0.9604\n",
            "91 Train accuracy: 0.96 Test accuracy: 0.962\n",
            "92 Train accuracy: 0.96 Test accuracy: 0.9606\n",
            "92 Train accuracy: 0.98 Test accuracy: 0.9616\n",
            "93 Train accuracy: 1.0 Test accuracy: 0.9613\n",
            "93 Train accuracy: 0.98 Test accuracy: 0.962\n",
            "94 Train accuracy: 0.96 Test accuracy: 0.961\n",
            "94 Train accuracy: 0.98 Test accuracy: 0.9619\n",
            "95 Train accuracy: 0.94 Test accuracy: 0.9606\n",
            "95 Train accuracy: 0.98 Test accuracy: 0.9624\n",
            "96 Train accuracy: 0.96 Test accuracy: 0.9618\n",
            "96 Train accuracy: 0.98 Test accuracy: 0.9626\n",
            "97 Train accuracy: 0.96 Test accuracy: 0.9616\n",
            "97 Train accuracy: 0.98 Test accuracy: 0.9627\n",
            "98 Train accuracy: 0.94 Test accuracy: 0.9616\n",
            "98 Train accuracy: 0.98 Test accuracy: 0.9631\n",
            "99 Train accuracy: 0.92 Test accuracy: 0.9625\n",
            "Time running:  295.012592792511\n",
            "99 Train accuracy: 0.96 Test accuracy: 0.9629\n",
            "Time running:  295.20606660842896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSjt3n4cWX0H",
        "colab_type": "text"
      },
      "source": [
        "As you can see from the output, the two programs are running in parallel, hence each of them must be using no more than half of the entire GPU memory, which is what we wanted to obtain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lHEV_cLTOJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}