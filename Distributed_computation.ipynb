{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed computation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOahE1cQALZpCApXWoV7KF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaLanzillotta/TensorflowEssentials/blob/master/Distributed_computation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxJc2x7KxSp",
        "colab_type": "text"
      },
      "source": [
        "# Distributing Tensorflow computation\n",
        "\n",
        "> [Tensorflow] gives you full control over how to split (or replicate) your computation graph across devices and servers, and it lets you parallelize and synchronize operations in flexible ways so you can choose between all sorts of parallelization approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjjzpinbLMFk",
        "colab_type": "text"
      },
      "source": [
        "## Parallelizing simple graphs across several GPUs on a single machine.\n",
        "\n",
        "In order to run TensorFlow on multiple GPU cards, you first need to make sure your GPU cards have NVidia Compute Capability.\n",
        "You must then **download and install the appropriate version of the CUDA and cuDNN libraries**, and set a few environment variables so TensorFlow knows where to find CUDA and cuDNN. \n",
        "\n",
        "> #### What is CUDA?  \n",
        "Short for \"Compute Unified Device Architecture\", it's both a parallel computing platform and a library created  by Nvidia allowing developers to use CUDA-enabled GPUs for general purpose processing. The CUDA platform is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels. \n",
        "\n",
        "> #### What about CuDNN?\n",
        "Short for CUDA Deep Neural Network library, a GPU-accelerated library of primitives for DNNs created by Nvidia. It provides optimized implementations of common DNN computations such as activation layers, normalization, forward and backward convolutions, and pooling.\n",
        "\n",
        "Let's look at what the Google server we're running on has to offer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX6FDvyvIGLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "739c9989-7403-48f0-a580-dd7274087d22"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 23 13:30:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE9lQAjJK5pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "158948d1-1e32-4b06-ac22-1aca45e156f8"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPJ4yfkPxaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b7b75a81-5958-4e22-f45f-de1cbe9bd12f"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.list_devices()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 11864881681466060498),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1397507663453625933),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 7947584449248635740),\n",
              " _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11330115994, 10096098157676641914)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCSlwI1bSZWH",
        "colab_type": "text"
      },
      "source": [
        "    Side note: \n",
        "    to test the following code snippets \n",
        "    I am going to use a python script \n",
        "    that builds and trains a DNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglatpauQEHF",
        "colab_type": "text"
      },
      "source": [
        "### Managing GPU RAM \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSp-q9hsQMXr",
        "colab_type": "text"
      },
      "source": [
        "To avoid that each Tensorflow process occupies the whole GPU RAM we can force each process to run on a single GPU card.<br>\n",
        "We can obtain it by setting the ```CUDA_VISIBLE_DEVICES``` environment variable as follows:\n",
        "\n",
        "```CUDA_VISIBLE_DEVICES=0,1 python3 program_1.py```\n",
        "\n",
        "```CUDA_VISIBLE_DEVICES=3,2 python3 program_2.py```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vode_MORP3H",
        "colab_type": "text"
      },
      "source": [
        "Another option is to tell TensorFlow to grab only a fraction of the memory. \n",
        "The following code does the job:\n",
        "\n",
        "```\n",
        "    # At the beginning of the script:\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 0.5 \n",
        "    # And when you create a session:\n",
        "    session = tf.Session(config=config)\n",
        "  ```\n",
        "I added the above code in the ```dnn.py``` script and in the following cell I am running it twice (I know it doesn't really make sense, but it serves the point).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxuBboIGSFJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be4acbab-07d7-43a2-dd4c-2aaa3a7add00"
      },
      "source": [
        "!python3 dnn.py & python3 dnn.py  & nvidia-smi"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 23 13:57:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    58W / 149W |     69MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "WARNING:tensorflow:From dnn.py:22: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:22: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:51: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:51: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:93: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:93: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:100: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:100: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:117: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:118: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:117: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:118: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:129: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From dnn.py:129: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From dnn.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-23 13:57:20.589172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-23 13:57:20.589671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15cad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.589863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-23 13:57:20.594050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-23 13:57:20.599698: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-23 13:57:20.600135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23f0d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.600305: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-23 13:57:20.603542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-23 13:57:20.670663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.672050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15caf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.672087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-23 13:57:20.672459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.673219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-23 13:57:20.673684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.676667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:20.679730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-23 13:57:20.680384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-23 13:57:20.683925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-23 13:57:20.685195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-23 13:57:20.690967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-23 13:57:20.691168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.692455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.693649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-23 13:57:20.693891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.693996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.695983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23f0f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-23 13:57:20.696024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-23 13:57:20.696282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.697084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-23 13:57:20.697398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.698343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-23 13:57:20.698596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-23 13:57:20.698808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-23 13:57:20.699327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.699546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:20.700765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.701125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-23 13:57:20.701577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-23 13:57:20.702212: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-23 13:57:20.702482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5720 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2020-04-23 13:57:20.703416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-23 13:57:20.704450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-23 13:57:20.708771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-23 13:57:20.708963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.709952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.710788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-23 13:57:20.710894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-23 13:57:20.712691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-23 13:57:20.712732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-23 13:57:20.712755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-23 13:57:20.712981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.714735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-23 13:57:20.715865: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-23 13:57:20.715920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5720 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From dnn.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From dnn.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2020-04-23 13:57:21.531883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-23 13:57:21.540723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "0 Train accuracy: 0.66 Test accuracy: 0.7465\n",
            "0 Train accuracy: 0.9 Test accuracy: 0.7593\n",
            "1 Train accuracy: 0.86 Test accuracy: 0.8348\n",
            "1 Train accuracy: 0.74 Test accuracy: 0.8427\n",
            "2 Train accuracy: 0.88 Test accuracy: 0.8644\n",
            "2 Train accuracy: 0.82 Test accuracy: 0.8683\n",
            "3 Train accuracy: 0.76 Test accuracy: 0.8806\n",
            "3 Train accuracy: 0.86 Test accuracy: 0.8823\n",
            "4 Train accuracy: 0.88 Test accuracy: 0.8904\n",
            "4 Train accuracy: 0.86 Test accuracy: 0.8928\n",
            "5 Train accuracy: 0.92 Test accuracy: 0.8969\n",
            "5 Train accuracy: 0.94 Test accuracy: 0.8988\n",
            "6 Train accuracy: 0.9 Test accuracy: 0.9018\n",
            "6 Train accuracy: 0.88 Test accuracy: 0.9033\n",
            "7 Train accuracy: 0.9 Test accuracy: 0.9068\n",
            "7 Train accuracy: 0.88 Test accuracy: 0.907\n",
            "8 Train accuracy: 0.92 Test accuracy: 0.9108\n",
            "8 Train accuracy: 0.92 Test accuracy: 0.9104\n",
            "9 Train accuracy: 0.96 Test accuracy: 0.9142\n",
            "9 Train accuracy: 0.9 Test accuracy: 0.9125\n",
            "10 Train accuracy: 0.9 Test accuracy: 0.9176\n",
            "10 Train accuracy: 0.92 Test accuracy: 0.914\n",
            "11 Train accuracy: 0.9 Test accuracy: 0.9189\n",
            "11 Train accuracy: 0.9 Test accuracy: 0.9167\n",
            "12 Train accuracy: 0.94 Test accuracy: 0.9213\n",
            "12 Train accuracy: 0.92 Test accuracy: 0.9178\n",
            "13 Train accuracy: 0.92 Test accuracy: 0.9232\n",
            "13 Train accuracy: 0.92 Test accuracy: 0.9194\n",
            "14 Train accuracy: 0.9 Test accuracy: 0.9246\n",
            "14 Train accuracy: 0.96 Test accuracy: 0.9208\n",
            "15 Train accuracy: 0.92 Test accuracy: 0.9264\n",
            "15 Train accuracy: 0.92 Test accuracy: 0.9228\n",
            "16 Train accuracy: 0.96 Test accuracy: 0.9279\n",
            "16 Train accuracy: 0.92 Test accuracy: 0.9243\n",
            "17 Train accuracy: 0.94 Test accuracy: 0.9291\n",
            "17 Train accuracy: 0.86 Test accuracy: 0.9251\n",
            "18 Train accuracy: 0.98 Test accuracy: 0.9305\n",
            "18 Train accuracy: 0.94 Test accuracy: 0.9266\n",
            "19 Train accuracy: 0.9 Test accuracy: 0.9314\n",
            "19 Train accuracy: 0.94 Test accuracy: 0.9277\n",
            "20 Train accuracy: 0.92 Test accuracy: 0.9326\n",
            "20 Train accuracy: 0.92 Test accuracy: 0.9286\n",
            "21 Train accuracy: 0.92 Test accuracy: 0.9343\n",
            "21 Train accuracy: 0.96 Test accuracy: 0.9296\n",
            "22 Train accuracy: 0.92 Test accuracy: 0.9355\n",
            "22 Train accuracy: 0.94 Test accuracy: 0.9309\n",
            "23 Train accuracy: 0.94 Test accuracy: 0.9358\n",
            "23 Train accuracy: 0.8 Test accuracy: 0.931\n",
            "24 Train accuracy: 0.96 Test accuracy: 0.9362\n",
            "24 Train accuracy: 1.0 Test accuracy: 0.9313\n",
            "25 Train accuracy: 0.94 Test accuracy: 0.9374\n",
            "25 Train accuracy: 1.0 Test accuracy: 0.934\n",
            "26 Train accuracy: 0.92 Test accuracy: 0.938\n",
            "26 Train accuracy: 0.84 Test accuracy: 0.9334\n",
            "27 Train accuracy: 0.88 Test accuracy: 0.9383\n",
            "27 Train accuracy: 0.96 Test accuracy: 0.9349\n",
            "28 Train accuracy: 0.96 Test accuracy: 0.9395\n",
            "28 Train accuracy: 0.96 Test accuracy: 0.9353\n",
            "29 Train accuracy: 0.9 Test accuracy: 0.939\n",
            "29 Train accuracy: 0.98 Test accuracy: 0.9364\n",
            "30 Train accuracy: 0.94 Test accuracy: 0.9404\n",
            "30 Train accuracy: 0.96 Test accuracy: 0.9369\n",
            "31 Train accuracy: 0.92 Test accuracy: 0.9402\n",
            "31 Train accuracy: 0.98 Test accuracy: 0.9366\n",
            "32 Train accuracy: 0.98 Test accuracy: 0.9417\n",
            "32 Train accuracy: 0.96 Test accuracy: 0.9369\n",
            "33 Train accuracy: 0.96 Test accuracy: 0.9418\n",
            "33 Train accuracy: 0.98 Test accuracy: 0.9379\n",
            "34 Train accuracy: 0.9 Test accuracy: 0.9417\n",
            "34 Train accuracy: 0.88 Test accuracy: 0.9397\n",
            "35 Train accuracy: 0.94 Test accuracy: 0.9425\n",
            "35 Train accuracy: 0.94 Test accuracy: 0.9396\n",
            "36 Train accuracy: 0.96 Test accuracy: 0.9435\n",
            "36 Train accuracy: 0.92 Test accuracy: 0.9402\n",
            "37 Train accuracy: 0.96 Test accuracy: 0.9443\n",
            "37 Train accuracy: 0.96 Test accuracy: 0.9402\n",
            "38 Train accuracy: 0.9 Test accuracy: 0.9447\n",
            "38 Train accuracy: 0.96 Test accuracy: 0.9412\n",
            "39 Train accuracy: 0.96 Test accuracy: 0.9457\n",
            "39 Train accuracy: 0.92 Test accuracy: 0.9423\n",
            "40 Train accuracy: 0.94 Test accuracy: 0.9458\n",
            "40 Train accuracy: 0.88 Test accuracy: 0.9421\n",
            "41 Train accuracy: 0.98 Test accuracy: 0.9448\n",
            "41 Train accuracy: 0.96 Test accuracy: 0.9426\n",
            "42 Train accuracy: 0.98 Test accuracy: 0.9466\n",
            "42 Train accuracy: 0.96 Test accuracy: 0.9422\n",
            "43 Train accuracy: 0.96 Test accuracy: 0.9476\n",
            "43 Train accuracy: 0.88 Test accuracy: 0.9436\n",
            "44 Train accuracy: 0.96 Test accuracy: 0.9473\n",
            "44 Train accuracy: 0.9 Test accuracy: 0.9432\n",
            "45 Train accuracy: 0.94 Test accuracy: 0.9482\n",
            "45 Train accuracy: 1.0 Test accuracy: 0.9446\n",
            "46 Train accuracy: 0.96 Test accuracy: 0.9485\n",
            "46 Train accuracy: 0.94 Test accuracy: 0.9453\n",
            "47 Train accuracy: 0.96 Test accuracy: 0.9499\n",
            "47 Train accuracy: 0.94 Test accuracy: 0.945\n",
            "48 Train accuracy: 0.94 Test accuracy: 0.9493\n",
            "48 Train accuracy: 0.96 Test accuracy: 0.9453\n",
            "49 Train accuracy: 0.96 Test accuracy: 0.9493\n",
            "49 Train accuracy: 0.94 Test accuracy: 0.9457\n",
            "50 Train accuracy: 0.98 Test accuracy: 0.9493\n",
            "50 Train accuracy: 0.98 Test accuracy: 0.9464\n",
            "51 Train accuracy: 0.92 Test accuracy: 0.9513\n",
            "51 Train accuracy: 0.96 Test accuracy: 0.9469\n",
            "52 Train accuracy: 0.98 Test accuracy: 0.9522\n",
            "52 Train accuracy: 1.0 Test accuracy: 0.9473\n",
            "53 Train accuracy: 0.92 Test accuracy: 0.9517\n",
            "53 Train accuracy: 0.98 Test accuracy: 0.9476\n",
            "54 Train accuracy: 0.96 Test accuracy: 0.9522\n",
            "54 Train accuracy: 0.96 Test accuracy: 0.948\n",
            "55 Train accuracy: 0.96 Test accuracy: 0.9524\n",
            "55 Train accuracy: 0.96 Test accuracy: 0.9489\n",
            "56 Train accuracy: 0.96 Test accuracy: 0.9527\n",
            "56 Train accuracy: 0.96 Test accuracy: 0.9486\n",
            "57 Train accuracy: 0.98 Test accuracy: 0.9536\n",
            "57 Train accuracy: 0.98 Test accuracy: 0.9494\n",
            "58 Train accuracy: 0.98 Test accuracy: 0.9543\n",
            "58 Train accuracy: 0.9 Test accuracy: 0.9499\n",
            "59 Train accuracy: 0.98 Test accuracy: 0.9546\n",
            "59 Train accuracy: 0.98 Test accuracy: 0.9504\n",
            "60 Train accuracy: 0.94 Test accuracy: 0.9543\n",
            "60 Train accuracy: 0.98 Test accuracy: 0.9504\n",
            "61 Train accuracy: 0.96 Test accuracy: 0.9549\n",
            "61 Train accuracy: 0.96 Test accuracy: 0.9506\n",
            "62 Train accuracy: 0.98 Test accuracy: 0.9547\n",
            "62 Train accuracy: 0.96 Test accuracy: 0.9518\n",
            "63 Train accuracy: 0.98 Test accuracy: 0.9558\n",
            "63 Train accuracy: 0.98 Test accuracy: 0.9519\n",
            "64 Train accuracy: 0.98 Test accuracy: 0.956\n",
            "64 Train accuracy: 1.0 Test accuracy: 0.9523\n",
            "65 Train accuracy: 0.98 Test accuracy: 0.9557\n",
            "65 Train accuracy: 0.96 Test accuracy: 0.9529\n",
            "66 Train accuracy: 0.92 Test accuracy: 0.9563\n",
            "66 Train accuracy: 1.0 Test accuracy: 0.9523\n",
            "67 Train accuracy: 0.96 Test accuracy: 0.9565\n",
            "67 Train accuracy: 0.96 Test accuracy: 0.9527\n",
            "68 Train accuracy: 0.96 Test accuracy: 0.9565\n",
            "68 Train accuracy: 1.0 Test accuracy: 0.9535\n",
            "69 Train accuracy: 0.94 Test accuracy: 0.957\n",
            "69 Train accuracy: 0.94 Test accuracy: 0.9538\n",
            "70 Train accuracy: 0.94 Test accuracy: 0.9577\n",
            "70 Train accuracy: 0.98 Test accuracy: 0.9549\n",
            "71 Train accuracy: 1.0 Test accuracy: 0.9574\n",
            "71 Train accuracy: 0.94 Test accuracy: 0.9544\n",
            "72 Train accuracy: 0.94 Test accuracy: 0.9576\n",
            "72 Train accuracy: 1.0 Test accuracy: 0.955\n",
            "73 Train accuracy: 0.94 Test accuracy: 0.9573\n",
            "73 Train accuracy: 0.98 Test accuracy: 0.9563\n",
            "74 Train accuracy: 0.86 Test accuracy: 0.9579\n",
            "74 Train accuracy: 0.92 Test accuracy: 0.9557\n",
            "75 Train accuracy: 0.96 Test accuracy: 0.958\n",
            "75 Train accuracy: 0.94 Test accuracy: 0.956\n",
            "76 Train accuracy: 0.98 Test accuracy: 0.958\n",
            "76 Train accuracy: 0.96 Test accuracy: 0.9563\n",
            "77 Train accuracy: 0.96 Test accuracy: 0.9584\n",
            "77 Train accuracy: 0.92 Test accuracy: 0.9565\n",
            "78 Train accuracy: 0.96 Test accuracy: 0.9568\n",
            "78 Train accuracy: 1.0 Test accuracy: 0.9589\n",
            "79 Train accuracy: 0.98 Test accuracy: 0.9574\n",
            "79 Train accuracy: 0.98 Test accuracy: 0.9598\n",
            "80 Train accuracy: 0.94 Test accuracy: 0.9577\n",
            "80 Train accuracy: 0.98 Test accuracy: 0.9591\n",
            "81 Train accuracy: 0.96 Test accuracy: 0.9577\n",
            "81 Train accuracy: 0.94 Test accuracy: 0.9598\n",
            "82 Train accuracy: 0.98 Test accuracy: 0.9578\n",
            "82 Train accuracy: 0.94 Test accuracy: 0.9596\n",
            "83 Train accuracy: 0.96 Test accuracy: 0.9588\n",
            "83 Train accuracy: 0.98 Test accuracy: 0.9598\n",
            "84 Train accuracy: 0.98 Test accuracy: 0.9584\n",
            "84 Train accuracy: 0.96 Test accuracy: 0.96\n",
            "85 Train accuracy: 0.98 Test accuracy: 0.9586\n",
            "85 Train accuracy: 0.96 Test accuracy: 0.96\n",
            "86 Train accuracy: 0.94 Test accuracy: 0.9591\n",
            "86 Train accuracy: 1.0 Test accuracy: 0.9608\n",
            "87 Train accuracy: 1.0 Test accuracy: 0.9604\n",
            "87 Train accuracy: 0.98 Test accuracy: 0.961\n",
            "88 Train accuracy: 1.0 Test accuracy: 0.9597\n",
            "88 Train accuracy: 0.98 Test accuracy: 0.9615\n",
            "89 Train accuracy: 0.98 Test accuracy: 0.9604\n",
            "89 Train accuracy: 0.96 Test accuracy: 0.9618\n",
            "90 Train accuracy: 0.98 Test accuracy: 0.9606\n",
            "90 Train accuracy: 0.96 Test accuracy: 0.9608\n",
            "91 Train accuracy: 0.98 Test accuracy: 0.9604\n",
            "91 Train accuracy: 0.96 Test accuracy: 0.962\n",
            "92 Train accuracy: 0.96 Test accuracy: 0.9606\n",
            "92 Train accuracy: 0.98 Test accuracy: 0.9616\n",
            "93 Train accuracy: 1.0 Test accuracy: 0.9613\n",
            "93 Train accuracy: 0.98 Test accuracy: 0.962\n",
            "94 Train accuracy: 0.96 Test accuracy: 0.961\n",
            "94 Train accuracy: 0.98 Test accuracy: 0.9619\n",
            "95 Train accuracy: 0.94 Test accuracy: 0.9606\n",
            "95 Train accuracy: 0.98 Test accuracy: 0.9624\n",
            "96 Train accuracy: 0.96 Test accuracy: 0.9618\n",
            "96 Train accuracy: 0.98 Test accuracy: 0.9626\n",
            "97 Train accuracy: 0.96 Test accuracy: 0.9616\n",
            "97 Train accuracy: 0.98 Test accuracy: 0.9627\n",
            "98 Train accuracy: 0.94 Test accuracy: 0.9616\n",
            "98 Train accuracy: 0.98 Test accuracy: 0.9631\n",
            "99 Train accuracy: 0.92 Test accuracy: 0.9625\n",
            "Time running:  295.012592792511\n",
            "99 Train accuracy: 0.96 Test accuracy: 0.9629\n",
            "Time running:  295.20606660842896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSjt3n4cWX0H",
        "colab_type": "text"
      },
      "source": [
        "As you can see from the output, the two programs are running in parallel, hence each of them must be using no more than half of the entire GPU memory, which is what we wanted to obtain. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex6WshBdX_wf",
        "colab_type": "text"
      },
      "source": [
        "### Placing graph nodes on the right devices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEJI4wMUYKmz",
        "colab_type": "text"
      },
      "source": [
        "Section 3.2.1 of the [Tensorflow whitepaper](http://download.tensorflow.org/paper/whitepaper2015.pdf) describes a beautiful placement algorithm (the *dynamic placement algorithm*) which was not released though, because it did not result in significant efficency improvements. <br>\n",
        "Tensorflow relies on another placing algorithm, called **simple placer**, which basically leaves the placement of operation to the user. \n",
        "\n",
        "> #### How does the simple placer works? \n",
        "Basically, by default all your nodes will be placed on GPU #0, if you have one, otherwise they'll be placed on CPU #0. However, you can change explicitly set the location of some nodes to be different. \n",
        "\n",
        "With the following lines of code we are placing some nodes on the CPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lHEV_cLTOJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device(\"/cpu:0\"): #selecting the cpu\n",
        "  # creating 2 nodes on the cpu\n",
        "  a = tf.Variable(3.0)\n",
        "  b = tf.Variable(4.0)\n",
        "\n",
        "c = a*b # note that we're back in the default settings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBSpIqfnaCBC",
        "colab_type": "text"
      },
      "source": [
        "We should have 2 nodes on the CPU and one on the GPU. Let's check whether this is actually the case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwz8XUoTaBBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "54cfaa8e-7819-40ec-a2b6-8226b371daa0"
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.log_device_placement = True\n",
        "sess = tf.Session(config=config)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8s6AYyCcp9l",
        "colab_type": "text"
      },
      "source": [
        "For a TensorFlow operation to run on a device, it needs to have an implementation for that device (calles a **kernel**).<br>\n",
        "With the following code we try to place an integer on GPU: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0AR2Y3ca_5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db99ce7c-2153-42bb-8eef-ecef0d482b3c"
      },
      "source": [
        "with tf.device(\"/gpu:0\"):\n",
        "  i = tf.Variable(10)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "init.run(session = sess)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  Variable_2 (VariableV2) /device:GPU:0\n  Variable_2/Assign (Assign) /device:GPU:0\n  Variable_2/read (Identity) /device:GPU:0\n\nOp: VariableV2\nNode attrs: shared_name=\"\", dtype=DT_INT32, container=\"\", shape=[]\nRegistered kernels:\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n\n\t [[{{node Variable_2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b3bc469c8d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     \"\"\"\n\u001b[0;32m-> 2439\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5440\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5442\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation Variable_2: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  Variable_2 (VariableV2) /device:GPU:0\n  Variable_2/Assign (Assign) /device:GPU:0\n  Variable_2/read (Identity) /device:GPU:0\n\nOp: VariableV2\nNode attrs: shared_name=\"\", dtype=DT_INT32, container=\"\", shape=[]\nRegistered kernels:\n  device='GPU'; dtype in [DT_INT64]\n  device='GPU'; dtype in [DT_DOUBLE]\n  device='GPU'; dtype in [DT_FLOAT]\n  device='GPU'; dtype in [DT_HALF]\n  device='CPU'\n\n\t [[node Variable_2 (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Variable_2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-b3bc469c8d5b>\", line 2, in <module>\n    i = tf.Variable(10)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1846, in _init_from_args\n    shape, self._initial_value.dtype.base_dtype, name=name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_state_ops.py\", line 1621, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw09xGd5db7c",
        "colab_type": "text"
      },
      "source": [
        "> \" Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\" <br>\n",
        "\n",
        "As you might have guessed, what Tensorflow is complaining about is that there's no GPU kernel for integer variables. \n",
        "\n",
        "Most of the fundamental operations have both a CPU and a GPU kernel. However, it can happen to get an exception as the one above. With the following code we are telling Tensorflow to automatically place on CPU if the GPU kernel is not available.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy4_D7msdSEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "651b0b3d-1202-44db-93d9-851bf0b869e5"
      },
      "source": [
        "with tf.device(\"/gpu:0\"):\n",
        "  i = tf.Variable(10)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "config = tf.ConfigProto() \n",
        "config.allow_soft_placement = True \n",
        "config.log_device_placement = True\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "init.run(session = sess)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v06sQvxbekog",
        "colab_type": "text"
      },
      "source": [
        "No exception! \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg6guawIfR8g",
        "colab_type": "text"
      },
      "source": [
        "### Parallel execution \n",
        "Tensorflow parallelizes every operation it can by default: \n",
        "> #### When TensorFlow runs a graph, it starts by finding out the list of nodes that need to be evaluated, and it counts how many dependencies each of them has. TensorFlow then starts evaluating the nodes with zero dependencies (i.e., source nodes). If these nodes are placed on separate devices, they obviously get evaluated in parallel. If they are placed on the same device, they get evaluated in different threads, so they may run in parallel too (in separate GPU threads or CPU cores).\n",
        "\n",
        "#### Inter-op threads VS Intra-op threads\n",
        "Tensorflow manages a thread pool on each device, so that it can run in parallel indipendent operations on a single devide by assigning each one to an *inter-op thread pool*. <br>\n",
        "Moreover, some operations' kernels support multi-threading: in that case Tensorflow assigns the operation an *intra-op thread pool*.<br>\n",
        "With the following lines of code we can manually control the number of threads per inter-op and intra-op pool. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCqjTAreiq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config.inter_op_parallelism_threads = 2\n",
        "config.intra_op_parallelism_threads = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtwceI6AhqIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}